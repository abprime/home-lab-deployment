model_list:
  # ---------- OpenAI ----------
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
  - model_name: o3-mini
    litellm_params:
      model: openai/o3-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true

  - model_name: o4-mini
    litellm_params:
      model: openai/o4-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true

  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
  - model_name: o3
    litellm_params:
      model: openai/o3
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true


  # ---------- Anthropic ----------
  - model_name: claude-opus-4
    litellm_params:
      model: anthropic/claude-opus-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true

  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY 
      merge_reasoning_content_in_choices: true

  - model_name: claude-sonnet-3.7
    litellm_params:
      model: anthropic/claude-3-7-sonnet-20250219
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true

  - model_name: claude-2.1
    litellm_params:
      model: anthropic/claude-2.1
      api_key: os.environ/ANTHROPIC_API_KEY   

  # ---------- Google Gemini ----------
  - model_name: gemini-2.5-pro-preview
    litellm_params:
      model: gemini/gemini-2.5-pro-preview-05-06
      api_key: os.environ/GEMINI_API_KEY
      merge_reasoning_content_in_choices: true 

  - model_name: gemini-2.5-flash-preview
    litellm_params:
      model: gemini/gemini-2.5-flash-preview-05-20
      api_key: os.environ/GEMINI_API_KEY
      merge_reasoning_content_in_choices: true  

  - model_name: gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro
      api_key: os.environ/GEMINI_API_KEY 

  - model_name: gemini-1.5-flash
    litellm_params:
      model: gemini/gemini-1.5-flash
      api_key: os.environ/GEMINI_API_KEY  

  # ---------- OpenRouter (best OSS/Boutique) ----------
  - model_name: llama-3-70b
    litellm_params:
      model: openrouter/meta-llama/llama-3-70b-instruct
      api_key: os.environ/OPENROUTER_API_KEY  

  - model_name: mixtral-8x22b
    litellm_params:
      model: openrouter/mistralai/mixtral-8x22b-instruct
      api_key: os.environ/OPENROUTER_API_KEY   

  - model_name: qwen3-30b
    litellm_params:
      model: openrouter/qwen/qwen3-30b-a3b
      api_key: os.environ/OPENROUTER_API_KEY 

  - model_name: deepseek-v3
    litellm_params:
      model: openrouter/deepseek/deepseek-chat
      api_key: os.environ/OPENROUTER_API_KEY 
      merge_reasoning_content_in_choices: true
  

general_settings:
  alerting: ["slack"] # Setup slack alerting - get alerts on LLM exceptions, Budget Alerts, Slow LLM Responses
  proxy_batch_write_at: 60 # Batch write spend updates every 60s
  database_connection_pool_limit: 10 # limit the number of database connections to = MAX Number of DB Connections/Number of instances of litellm proxy (Around 10-20 is good number)

  # OPTIONAL Best Practices
  disable_spend_logs: False # turn off writing each transaction to the db. We recommend doing this is you don't need to see Usage on the LiteLLM UI and are tracking metrics via Prometheus
  disable_error_logs: True # turn off writing LLM Exceptions to DB
  allow_requests_on_db_unavailable: False # Only USE when running LiteLLM on your VPC. Allow requests to still be processed even if the DB is unavailable. We recommend doing this if you're running LiteLLM on VPC that cannot be accessed from the public internet.

litellm_settings:
  request_timeout: 600 # raise Timeout error if call takes longer than 600 seconds. Default value is 6000seconds if not set
  set_verbose: False # Switch off Debug Logging, ensure your logs do not have any debugging on
  json_logs: true # Get debug logs in json format

  cache: True
  cache_params:
    type: redis
    host: redis

router_settings:
  routing_strategy: usage-based-routing-v2
  redis_host: redis
